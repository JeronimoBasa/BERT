# BERT: Bidirectional Encoder Representations from Transformers

It's a tool used in NLP which, in contrast with Word2Vec, BERT generates embedding under the context of the sentence for words that may have distinct meanings based on the context within the corresponding sentence.
